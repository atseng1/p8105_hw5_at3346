---
title: "p8105_hw5_at3346"
author: "Ashley Tseng"
date: "11/11/2019"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))

set.seed(10)
```



## Problem 1
```{r prob1}
iris_with_missing = iris %>% 
  janitor::clean_names() %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(species = as.character(species))


iris_func = function(x) { 
  
  if (is.numeric(x)){
      replace(x, is.na(x), round(mean(x, na.rm = TRUE), digits = 1))
  }
  
  else {
    replace (x, is.na(x), "virginica")
  }
  
}
  
iris_no_missing = map_df(iris_with_missing, ~iris_func(.x))
```



## Problem 2
```{r prob2.tidy}
file_names = tibble(
  name = list.files(path = "./data/", all.files = TRUE, no.. = TRUE),
  file_path = str_c("./data/", name))

source_func = function(x){
  read_csv(x)
}

long_study = file_names %>% 
  mutate(source_name = map(file_names$file_path, source_func)) %>% 
  unnest() %>% 
  janitor::clean_names() %>% 
  select(-file_path) %>% 
  separate(name, into = c("study_arm","subject_id", "file_type")) %>% 
  select(-file_type, -v1)
```


```{r prob2.plot1}
arm.labs = c("Control Arm", "Experimental Arm")
names(arm.labs) = c("con", "exp")

spaghetti = long_study %>% 
    pivot_longer(
    cols = starts_with("week_"),
    names_to = "week",
    names_prefix = "week_",
    values_to = "obs_value") %>% 
  group_by(study_arm) %>% 
  ggplot(aes(x = week, y = obs_value, color = subject_id, group = subject_id)) + 
  geom_path() +
  facet_grid("study_arm", labeller = labeller(study_arm = arm.labs)) +
  labs(
    title = "Observations On Each Subject Over Time By Study Arm",
    x = "Week",
    y = "Weekly Observation Value",
    color = "Subject ID") +
  theme(plot.title = element_text(hjust = 0.5))

spaghetti
```



Based on visually inspecting the spaghetti plot, the weekly observation values for subjects in the experimental arm of the study are, on average, higher than the weekly observation values for the control arm of the study. More specifically, by week 8, the weekly observation values of the control arm ranged from -0.53 to 2.35, while for the experimental arm the values ranged from 3.27 to 6.95.



## Problem 3
```{r prob3}
set.seed(10)

sim_regression = function(n = 30, beta0 = 2, beta1, var = 50) {
  
  sim_data = tibble(
    x = rnorm(n, mean = 0, sd = 1),
    y = beta0 + beta1 * x + rnorm(n, 0, var^0.5)
  )

  ls_fit = lm(y ~ x, data = sim_data)
  
  broom::tidy(ls_fit)
}

sim_results = 
  rerun(10000, sim_regression(n = 30, beta0 = 2, var = 50, beta1 = 0)) %>% 
  bind_rows() %>% 
  select(term, estimate, p.value) %>% 
  filter(term == "x")

sim_results_power = 
  tibble(beta1_values = c(0, 1, 2, 3, 4, 5, 6)) %>% 
  mutate(
    output_lists = map(.x = beta1_values, ~rerun(10000, sim_regression(beta1 = .x))),
    estimate_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs) %>% 
  select(beta1_values, term, estimate, p.value) %>% 
  filter(term == "x") 
```


```{r prob3.plot1}
sim_results_all =
  sim_results_power %>% 
  group_by(beta1_values) %>% 
  summarize(
    p_sum = sum(p.value < 0.05),
    p_total = p_sum/n()) %>% 
  ggplot(aes(x = beta1_values, y = p_total)) + 
  geom_bar(stat = "identity", fill = "sea green") +
  labs(
    title = "Association Between Effect Size & Power",
    x = "True Value of β1 (Effect Size)",
    y = "Proportion of Times The Null Was Rejected (Power)") +
  theme(plot.title = element_text(hjust = 0.5))

sim_results_all
```
 

As effect size (the true value of β1) increases, power (the proportion of times H0 was rejected) increases as well. At β1=0, the power is 0.0509, nearly at a value of 0. At β1=6, the power is 0.9823, nearly at a full value of 1. 

 
```{r prob3.plot2}
sim_results_esttrue =
  sim_results_power %>% 
  group_by(beta1_values) %>% 
  summarize(
    beta1est_avg = mean(estimate),
    beta1est_avg_sig = mean(estimate[p.value < 0.05], na.rm = TRUE)) %>% 
  ggplot(aes(x = beta1_values, y = beta1est_avg)) + 
  geom_bar(stat = "identity", fill = "sea green") +
  geom_point(aes(x = beta1_values, y = beta1est_avg_sig)) +
  labs(
    title = "True Values of β1 vs. Average Estimates of β̂1 & \n Average Estimates of β̂1 In Samples For Which H0 Was Rejected",
    x = "True Value of β1",
    y = "Average Estimate of β̂1") +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "bottom") +
  scale_y_continuous(breaks = seq(-1, 7, 1)) +
  scale_x_continuous(breaks = seq(0, 6, 1)) +
  scale_fill_identity(name = 'Legend', guide = 'legend',labels = c('True vs. Estimated Values of β1')) 

sim_results_esttrue
```


In this graph, the green bars show the average estimates of β̂1 and the black points show the average estimates of β̂1 only in samples for which the null was rejected. The true values of β1 are shown on the x-axis. The sample average of β̂1 across tests for which the null is rejected is not consistently equal to the true value of β1. For β1=4, 5, 6 the sample averages of β̂1 are approximately equal to the true value. However, for β1=0, 1, 2, 3 the sample averages of β̂1 are not equal to the true value. This is because larger effect sizes are easier to detect than smaller effect sizes and therefore easier to estimate. As a result, the sample averages of β̂1 for larger true values of β1 are more accurate.
